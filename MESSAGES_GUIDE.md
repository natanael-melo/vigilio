# üì± Vigilo - Guia de Mensagens e Payloads

Este documento descreve **todas as mensagens** que voc√™ receber√° no WhatsApp e **todos os payloads** enviados para o webhook n8n, com exemplos pr√°ticos de interpreta√ß√£o.

---

## üì± PARTE 1: Mensagens do WhatsApp

Todas as mensagens chegam via Evolution API no n√∫mero configurado em `NOTIFY_NUMBER`.

---

### 1Ô∏è‚É£ Mensagem de Inicializa√ß√£o

**Quando acontece:** Logo ap√≥s o agente iniciar (startup do container)

**Formato:**
```
‚úÖ Vigilo Iniciado

üñ•Ô∏è Host: servidor-producao
üïí 30/11/2025 14:30:15
```

**O que significa:**
- ‚úÖ O agente est√° rodando e operacional
- Todas as conex√µes (Evolution API, n8n, Docker) foram estabelecidas
- O monitoramento come√ßou

**A√ß√£o recomendada:** Nenhuma. √â apenas informativo.

---

### 2Ô∏è‚É£ Mensagem de Encerramento

**Quando acontece:** Quando o agente √© desligado (docker stop, SIGTERM, etc)

**Formato:**
```
üõë Vigilo Encerrado

üñ•Ô∏è Host: servidor-producao
üïí 30/11/2025 18:45:30

üìä Checagens realizadas: 1.445
```

**O que significa:**
- O agente foi desligado (intencional ou n√£o)
- Mostra quantas checagens foram feitas desde que iniciou

**A√ß√£o recomendada:** 
- Se foi intencional: OK
- Se n√£o esperava: Investigar logs do container

---

### 3Ô∏è‚É£ Alerta de CPU Cr√≠tica

**Quando acontece:** CPU ultrapassa o limiar configurado (padr√£o: 85%)

**Formato:**
```
‚ö†Ô∏è ALERTA VIGILO ‚ö†Ô∏è

üî¥ CPU em 92.5% (limite: 85.0%)

üïí 30/11/2025 15:20:10
```

**O que significa:**
- A CPU est√° sobrecarregada
- Pode causar lentid√£o ou travamentos
- O alerta tem cooldown de 30 minutos (n√£o reenvia se continuar alto)

**A√ß√£o recomendada:**
1. Verifique processos com `top` ou `htop`
2. Identifique processos consumindo muita CPU
3. Considere escalar recursos ou otimizar aplica√ß√µes

**Poss√≠veis causas:**
- Processo travado em loop
- Ataque DDoS
- Backup pesado rodando
- Aplica√ß√£o mal otimizada

---

### 4Ô∏è‚É£ Alerta de RAM Cr√≠tica

**Quando acontece:** Mem√≥ria RAM ultrapassa o limiar (padr√£o: 90%)

**Formato:**
```
‚ö†Ô∏è ALERTA VIGILO ‚ö†Ô∏è

üî¥ RAM em 95.2% (limite: 90.0%)

üïí 30/11/2025 15:25:33
```

**O que significa:**
- A mem√≥ria est√° quase esgotada
- Sistema pode come√ßar a usar SWAP (muito lento)
- Risco de OOM Killer matar processos

**A√ß√£o recomendada:**
1. Verifique uso de mem√≥ria: `free -h`
2. Identifique processos: `ps aux --sort=-%mem | head`
3. Considere reiniciar servi√ßos pesados
4. Avaliar upgrade de RAM

**Poss√≠veis causas:**
- Memory leak em aplica√ß√£o
- Cache muito grande
- Muitos containers rodando
- Banco de dados sem otimiza√ß√£o

---

### 5Ô∏è‚É£ Alerta de Disco Cr√≠tico

**Quando acontece:** Disco ultrapassa o limiar (padr√£o: 90%)

**Formato:**
```
‚ö†Ô∏è ALERTA VIGILO ‚ö†Ô∏è

üî¥ DISCO em 94.8% (limite: 90.0%)

üïí 30/11/2025 16:10:45
```

**O que significa:**
- O disco est√° quase cheio
- **CR√çTICO:** Sistema pode travar quando chegar a 100%
- Logs podem parar de funcionar

**A√ß√£o recomendada:**
1. Verifique uso: `df -h`
2. Identifique grandes arquivos: `du -sh /* | sort -h`
3. Limpe logs antigos: `/var/log/`
4. Limpe cache do Docker: `docker system prune -a`
5. Considere aumentar disco

**Poss√≠veis causas:**
- Logs n√£o rotacionados
- Backups antigos
- Imagens Docker acumuladas
- Arquivos tempor√°rios esquecidos

---

### 6Ô∏è‚É£ Alerta de Container N√£o Encontrado

**Quando acontece:** Um container da lista `WATCH_CONTAINERS` n√£o existe

**Formato:**
```
‚ö†Ô∏è ALERTA VIGILO ‚ö†Ô∏è

‚ùå Container 'postgres' n√£o encontrado!

üïí 30/11/2025 16:15:20
```

**O que significa:**
- Um container importante foi removido
- Ou o nome est√° errado na configura√ß√£o
- Servi√ßo pode estar indispon√≠vel

**A√ß√£o recomendada:**
1. Verifique se o container existe: `docker ps -a | grep postgres`
2. Se foi removido acidentalmente, recrie-o
3. Se mudou de nome, atualize `WATCH_CONTAINERS`

---

### 7Ô∏è‚É£ Alerta de Container Parado

**Quando acontece:** Container monitorado est√° parado/crashed

**Formato:**
```
‚ö†Ô∏è ALERTA VIGILO ‚ö†Ô∏è

üî¥ Container 'api_prod' est√° EXITED!

üïí 30/11/2025 16:20:15
```

**O que significa:**
- Um servi√ßo cr√≠tico est√° fora do ar
- Pode ter crasheado ou sido parado
- **URGENTE:** Servi√ßo indispon√≠vel

**A√ß√£o recomendada:**
1. Veja os logs: `docker logs api_prod --tail 100`
2. Tente reiniciar: `docker restart api_prod`
3. Se n√£o subir, verifique configura√ß√£o/erro
4. Considere rollback se foi ap√≥s deploy

**Status poss√≠veis:**
- `EXITED` - Saiu/crasheou
- `RESTARTING` - Tentando reiniciar
- `PAUSED` - Foi pausado manualmente
- `DEAD` - Morto (erro grave)

---

### 8Ô∏è‚É£ Alerta de Container Unhealthy

**Quando acontece:** Health check do Docker detectou problema

**Formato:**
```
‚ö†Ô∏è ALERTA VIGILO ‚ö†Ô∏è

‚ö†Ô∏è Container 'nginx' est√° UNHEALTHY!

üïí 30/11/2025 16:25:40
```

**O que significa:**
- Container est√° rodando MAS n√£o est√° saud√°vel
- Health check est√° falhando
- Servi√ßo pode estar lento ou com erro

**A√ß√£o recomendada:**
1. Verifique logs: `docker logs nginx --tail 50`
2. Inspecione health: `docker inspect nginx | grep -A 20 Health`
3. Teste manualmente o servi√ßo
4. Reinicie se necess√°rio

**Nota:** S√≥ funciona se o container tiver `HEALTHCHECK` configurado no Dockerfile.

---

### 9Ô∏è‚É£ Relat√≥rio Inicial

**Quando acontece:** Logo ap√≥s o agente iniciar (2-3 segundos depois da mensagem de inicializa√ß√£o)

**Formato:**
```
üöÄ RELAT√ìRIO INICIAL

üìä Relat√≥rio do Sistema

üü¢ CPU: 45.2%
üü¢ RAM: 65.8% (5.2GB / 8.0GB)
üü¢ Disco: 72.1% (350.5GB / 486.0GB)

‚è±Ô∏è Uptime: 15 days, 4:23:10
üî¢ Processos: 187

üê≥ Docker: 8 rodando / 2 parados

Status dos Containers:
üü¢ postgres ‚úì
üü¢ api_prod ‚úì
üü¢ nginx ‚úì

üì° Status do Agente
‚úÖ Checagens realizadas: 0
üì§ Heartbeats enviados: 1

üïí 30/11/2025 16:00:05
```

**O que significa:**
- Snapshot completo do estado inicial do servidor
- Confirma que todos os sistemas est√£o funcionando
- Mostra quais containers est√£o rodando
- **NOVO na v1.1:** Antes voc√™ tinha que esperar 4 horas

**A√ß√£o recomendada:** 
- Revisar e confirmar que est√° tudo OK
- Se houver algo cr√≠tico (üî¥), j√° sabe desde o in√≠cio

**Por qu√™ √© √∫til:**
- Visibilidade imediata ap√≥s restart
- Detecta problemas logo na inicializa√ß√£o
- N√£o precisa esperar pelo relat√≥rio peri√≥dico
- √ötil ap√≥s manuten√ß√µes

---

### üîü Relat√≥rio Peri√≥dico

**Quando acontece:** A cada X horas (configurado em `REPORT_HOURS`, padr√£o: 4h)

**Formato:**
```
üìä RELAT√ìRIO VIGILO

üìä Relat√≥rio do Sistema

üü¢ CPU: 45.2%
üü¢ RAM: 65.8% (5.2GB / 8.0GB)
üü¢ Disco: 72.1% (350.5GB / 486.0GB)

‚è±Ô∏è Uptime: 15 days, 4:23:10
üî¢ Processos: 187

üê≥ Docker: 8 rodando / 2 parados

Monitorados:
üü¢ postgres
üü¢ api_prod
üî¥ nginx

üì° Status do Agente
‚úÖ Checagens realizadas: 1.445
üì§ Heartbeats enviados: 1.443
‚ùå Falhas heartbeat: 2
üìä Taxa de sucesso: 99.86%

üïí 30/11/2025 16:00:05
```

**O que significa:**
- Resumo completo da sa√∫de do servidor
- **Sempre enviado** (n√£o tem cooldown)
- Mostra tamb√©m estat√≠sticas do pr√≥prio agente

**Interpreta√ß√£o dos emojis:**
- üü¢ = OK, dentro do limite
- üî¥ = Cr√≠tico, acima do limite
- ‚úÖ = Funcionando
- ‚ùå = Com problema

**A√ß√£o recomendada:** 
- Revisar e arquivar
- Se houver üî¥, investigar

---

## üéØ Resumo: Gravidade dos Alertas

| Emoji | Tipo | Gravidade | A√ß√£o |
|-------|------|-----------|------|
| ‚úÖ | Inicializa√ß√£o | Info | Nenhuma |
| üöÄ | Relat√≥rio inicial | Info | Revisar estado inicial |
| üõë | Encerramento | Aten√ß√£o | Verificar se esperado |
| üî¥ | CPU/RAM/Disco | Alta | Investigar imediatamente |
| ‚ùå | Container n√£o encontrado | Cr√≠tica | Verificar urgente |
| üî¥ | Container parado | Cr√≠tica | Reiniciar servi√ßo |
| ‚ö†Ô∏è | Container unhealthy | Alta | Investigar |
| üìä | Relat√≥rio peri√≥dico | Info | Revisar |

---

## üîî Sistema Anti-Spam (Cooldown)

Para evitar spam de mensagens:

- **Alertas de recursos (CPU/RAM/Disco):** Cooldown de 30 minutos (padr√£o)
- **Alertas de containers:** Cooldown de 30 minutos (padr√£o)
- **Relat√≥rios peri√≥dicos:** SEM cooldown (sempre enviados)
- **Inicializa√ß√£o/Encerramento:** SEM cooldown (eventos √∫nicos)

**Exemplo:**
```
15:00 - CPU em 90% ‚Üí ALERTA ENVIADO
15:10 - CPU em 92% ‚Üí N√ÉO ENVIA (cooldown)
15:20 - CPU em 88% ‚Üí N√ÉO ENVIA (cooldown)
15:35 - CPU em 91% ‚Üí ALERTA ENVIADO (cooldown expirou)
```

**Configura√ß√£o:** Altere `ALERT_COOLDOWN` em segundos (padr√£o: 1800 = 30min)

---

## üåê PARTE 2: Payloads do Webhook n8n

Todos os payloads s√£o enviados via **POST** com `Content-Type: application/json`

---

### 1Ô∏è‚É£ Heartbeat Normal (A cada 60s)

**Quando:** A cada ciclo de checagem (configurado em `CHECK_INTERVAL`)

**Payload:**
```json
{
  "agent_name": "servidor-producao",
  "status": "alive",
  "timestamp": 1701368400,
  "consecutive_failures": 0,
  "total_sent": 1445,
  "total_failed": 2,
  "stats": {
    "cpu_percent": 45.2,
    "ram_percent": 65.8,
    "disk_percent": 72.1,
    "uptime_seconds": 1324990
  }
}
```

**Como interpretar:**

| Campo | Tipo | Descri√ß√£o |
|-------|------|-----------|
| `agent_name` | string | Nome do servidor (hostname) |
| `status` | string | Sempre "alive" em heartbeats normais |
| `timestamp` | integer | Unix timestamp (segundos desde 1970) |
| `consecutive_failures` | integer | Falhas consecutivas de heartbeat (0 = OK) |
| `total_sent` | integer | Total de heartbeats enviados com sucesso |
| `total_failed` | integer | Total de falhas de envio |
| `stats.cpu_percent` | float | CPU atual em % |
| `stats.ram_percent` | float | RAM atual em % |
| `stats.disk_percent` | float | Disco atual em % |
| `stats.uptime_seconds` | integer | Tempo ligado em segundos |

**Uso recomendado no n8n:**
1. Armazenar em banco de dados para hist√≥rico
2. Criar alerta se n√£o receber heartbeat por 5 minutos
3. Gerar gr√°ficos de m√©tricas ao longo do tempo
4. Trigger para a√ß√µes se `consecutive_failures` > 5

---

### 2Ô∏è‚É£ Evento de Inicializa√ß√£o

**Quando:** Logo ap√≥s o agente iniciar

**Payload:**
```json
{
  "agent_name": "servidor-producao",
  "status": "alive",
  "timestamp": 1701368400,
  "consecutive_failures": 0,
  "total_sent": 1,
  "total_failed": 0,
  "event_type": "startup",
  "event_data": {
    "message": "Vigilo Agent iniciado",
    "hostname": "servidor-producao"
  }
}
```

**Como interpretar:**

| Campo | Descri√ß√£o |
|-------|-----------|
| `event_type` | Sempre "startup" |
| `event_data.message` | Mensagem descritiva |
| `event_data.hostname` | Nome do servidor |

**Uso recomendado no n8n:**
- Registrar em log de eventos
- Enviar notifica√ß√£o para Slack/Telegram
- Atualizar dashboard de status

---

### 3Ô∏è‚É£ Evento de Encerramento

**Quando:** Quando o agente √© desligado

**Payload:**
```json
{
  "agent_name": "servidor-producao",
  "status": "alive",
  "timestamp": 1701385200,
  "consecutive_failures": 0,
  "total_sent": 1445,
  "total_failed": 2,
  "event_type": "shutdown",
  "event_data": {
    "message": "Vigilo Agent encerrado",
    "checks_performed": 1445
  }
}
```

**Como interpretar:**

| Campo | Descri√ß√£o |
|-------|-----------|
| `event_type` | Sempre "shutdown" |
| `event_data.message` | Mensagem descritiva |
| `event_data.checks_performed` | Quantas checagens foram feitas |

**Uso recomendado no n8n:**
- Registrar downtime
- Alertar se n√£o foi agendado
- Calcular uptime

---

### 4Ô∏è‚É£ Evento de Alertas Gerados

**Quando:** Sempre que alertas s√£o detectados e enviados

**Payload:**
```json
{
  "agent_name": "servidor-producao",
  "status": "alive",
  "timestamp": 1701370200,
  "consecutive_failures": 0,
  "total_sent": 150,
  "total_failed": 0,
  "event_type": "alerts_generated",
  "event_data": {
    "alert_count": 3,
    "alert_types": [
      "CPU_CRITICAL",
      "CONTAINER_NOT_RUNNING",
      "RAM_CRITICAL"
    ]
  }
}
```

**Como interpretar:**

| Campo | Descri√ß√£o |
|-------|-----------|
| `event_type` | Sempre "alerts_generated" |
| `event_data.alert_count` | Quantos alertas foram gerados |
| `event_data.alert_types` | Lista dos tipos de alerta |

**Tipos de alerta poss√≠veis:**
- `CPU_CRITICAL` - CPU acima do limite
- `RAM_CRITICAL` - RAM acima do limite
- `DISK_CRITICAL` - Disco acima do limite
- `CONTAINER_NOT_FOUND` - Container n√£o encontrado
- `CONTAINER_NOT_RUNNING` - Container parado
- `CONTAINER_UNHEALTHY` - Container com problema
- `DOCKER_CONNECTION_ERROR` - Erro ao conectar no Docker

**Uso recomendado no n8n:**
- Escalar alertas para PagerDuty/OpsGenie
- Criar tickets autom√°ticos
- Disparar runbooks de corre√ß√£o
- Notificar equipe de plant√£o

---

## üìä Workflow Sugerido no n8n

### Workflow B√°sico de Monitoramento

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Webhook   ‚îÇ (POST /webhook/vigilo)
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
       ‚îÇ                                     ‚îÇ
       ‚ñº                                     ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ IF event_type‚îÇ                     ‚îÇ Set Variable ‚îÇ
‚îÇ   exists?    ‚îÇ                     ‚îÇ last_heartbeat‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ startup ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ [Log + Notificar]
       ‚îÇ
       ‚îú‚îÄ‚îÄ‚îÄ shutdown ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∫ [Log + Verificar se esperado]
       ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ alerts_generated ‚îÄ‚îÄ‚îÄ‚ñ∫ [Escalar para equipe]


‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Workflow Paralelo: Detector de Agente Offline ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Cron (5min) ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Verificar se ‚îÇ (last_heartbeat)
‚îÇ recebeu HB   ‚îÇ
‚îÇ nos √∫ltimos  ‚îÇ
‚îÇ   5 minutos  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
       ‚îÇ
       ‚îî‚îÄ‚îÄ‚îÄ N√ÉO ‚îÄ‚îÄ‚ñ∫ [ALERTA: Agente Offline!]
```

### Exemplo de C√≥digo n8n (IF Node)

```javascript
// Detecta tipo de evento
if ($json.event_type === 'startup') {
  return [{ json: { action: 'log_startup', data: $json } }];
}

if ($json.event_type === 'shutdown') {
  return [{ json: { action: 'log_shutdown', data: $json } }];
}

if ($json.event_type === 'alerts_generated') {
  // Se tem alertas cr√≠ticos, escala
  const criticalAlerts = $json.event_data.alert_types.filter(type => 
    type.includes('CRITICAL') || 
    type.includes('CONTAINER_NOT_RUNNING')
  );
  
  if (criticalAlerts.length > 0) {
    return [{ json: { action: 'escalate', data: $json, critical: true } }];
  }
}

// Heartbeat normal
return [{ json: { action: 'store_metrics', data: $json } }];
```

---

## üîç Troubleshooting de Payloads

### Problema: N√£o recebo payloads no n8n

**Checklist:**
1. ‚úÖ Webhook n8n est√° ativo? (modo Production)
2. ‚úÖ URL est√° correta? (incluindo https://)
3. ‚úÖ Firewall permite conex√µes do servidor?
4. ‚úÖ Container Vigilo est√° rodando?
5. ‚úÖ Verificar logs: `docker logs vigilo-agent | grep heartbeat`

**Teste manual:**
```bash
curl -X POST https://seu-n8n.com/webhook/vigilo \
  -H "Content-Type: application/json" \
  -d '{
    "agent_name": "teste",
    "status": "alive",
    "timestamp": 1701368400
  }'
```

### Problema: Payloads chegam, mas com campos faltando

**Poss√≠vel causa:** Vers√£o antiga do Vigilo

**Solu√ß√£o:**
```bash
docker-compose pull
docker-compose up -d
```

---

## üìñ Gloss√°rio de Termos

| Termo | Significado |
|-------|-------------|
| **Heartbeat** | Sinal de vida enviado periodicamente |
| **Cooldown** | Per√≠odo de espera antes de reenviar alerta |
| **Payload** | Dados JSON enviados no webhook |
| **Health Check** | Verifica√ß√£o autom√°tica de sa√∫de do container |
| **Uptime** | Tempo que o sistema est√° ligado |
| **OOM Killer** | Mecanismo do Linux que mata processos quando RAM acaba |
| **Threshold** | Limiar/limite configurado para alertas |
| **Unix Timestamp** | Segundos desde 01/01/1970 00:00:00 UTC |

---

## üéØ Exemplos Pr√°ticos de Uso

### Exemplo 1: Calcular Uptime no n8n

```javascript
const uptimeSeconds = $json.stats.uptime_seconds;
const days = Math.floor(uptimeSeconds / 86400);
const hours = Math.floor((uptimeSeconds % 86400) / 3600);
const minutes = Math.floor((uptimeSeconds % 3600) / 60);

return {
  json: {
    uptime: `${days}d ${hours}h ${minutes}m`,
    uptime_days: days
  }
};
```

### Exemplo 2: Detectar Tend√™ncia de Crescimento de Disco

```javascript
// Armazena hist√≥rico em banco
// Compara com m√©dia dos √∫ltimos 7 dias

const currentDisk = $json.stats.disk_percent;
const averageLast7Days = 75.0; // Buscar do banco

const growthRate = ((currentDisk - averageLast7Days) / averageLast7Days) * 100;

if (growthRate > 10) {
  // Disco crescendo mais de 10% em rela√ß√£o √† m√©dia
  return [{ json: { alert: 'DISK_GROWING_FAST', rate: growthRate } }];
}
```

### Exemplo 3: Converter Timestamp para Data Leg√≠vel

```javascript
const timestamp = $json.timestamp;
const date = new Date(timestamp * 1000);

return {
  json: {
    readable_date: date.toLocaleString('pt-BR', {
      timeZone: 'America/Sao_Paulo'
    })
  }
};
```

---

## ‚úÖ Checklist de Implementa√ß√£o

Para voc√™ ou seus clientes:

- [ ] Webhook n8n configurado e testado
- [ ] Workflow para armazenar heartbeats
- [ ] Alerta quando agente fica offline (> 5min sem heartbeat)
- [ ] Workflow para processar eventos de startup/shutdown
- [ ] Workflow para escalar alertas cr√≠ticos
- [ ] Dashboard com m√©tricas hist√≥ricas (opcional)
- [ ] Documenta√ß√£o interna de procedimentos de resposta
- [ ] Testes com alertas simulados

---

## üìû Suporte

Se tiver d√∫vidas sobre alguma mensagem ou payload:

1. Consulte este guia
2. Verifique logs: `docker logs vigilo-agent`
3. Execute teste: `python3 test_config.py`
4. Abra issue no GitHub

---

**√öltima atualiza√ß√£o:** 30/11/2025  
**Vers√£o do Vigilo:** 1.0.0

